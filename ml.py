# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HIaWB-PM7rTZrVkSBmhkw1E-Faed6akM
"""
import streamlit as st
import pandas as pd
import numpy as np
import csv
import matplotlib.pyplot as plt

# Scikit-learn (Modelos de Regresi√≥n)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error


# -----------------------------------------------------------
# FUNCI√ìN PARA CARGAR CSV Y DETECTAR DELIMITADOR AUTOM√ÅTICO
# -----------------------------------------------------------
def cargar_csv(uploaded_file):
    contenido = uploaded_file.read().decode('latin-1', errors='ignore')
    uploaded_file.seek(0)

    try:
        # Intentar detectar el delimitador
        dialect = csv.Sniffer().sniff(contenido.splitlines()[0])
        sep = dialect.delimiter
    except:
        sep = ','  # Si no detecta, usamos coma por defecto

    # Leer el archivo con el delimitador detectado
    df = pd.read_csv(uploaded_file, sep=sep, engine="python")
    df.columns = df.columns.str.strip()

    # Convertir todas las columnas posibles a num√©ricas (manejo de comas/espacios)
    for col in df.columns:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", "", regex=False) # Quita comas
            .str.strip() # Quita espacios
        )
        df[col] = pd.to_numeric(df[col], errors='ignore')

    return df


# -----------------------------------------------------------
# M√âTRICAS
# -----------------------------------------------------------
def calculate_metrics(y_true, y_pred, subset_name):
    return {
        'Conjunto': subset_name,
        'R2': r2_score(y_true, y_pred),
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'Bias': np.mean(y_pred - y_true)
    }


# -----------------------------------------------------------
# INTERFAZ STREAMLIT
# -----------------------------------------------------------

st.set_page_config(page_title="Modelos de Machine Learning - Regresi√≥n", layout="wide")

st.title("üåä Modelos de Machine Learning - Regresi√≥n")
st.markdown("---")

with st.sidebar:
    st.header("1. Cargar Datos CSV")
    uploaded_file = st.file_uploader("Seleccione archivo CSV", type=['csv'])

df = None
if uploaded_file:
    df = cargar_csv(uploaded_file)

    if df.shape[0] == 0:
        st.error("‚ö† El archivo se carg√≥ pero **no contiene filas v√°lidas**. Revisa el delimitador o el formato.")
        st.stop()
    else:
        st.success(f"‚úÖ Archivo cargado correctamente: {df.shape[0]} filas, {df.shape[1]} columnas.")
        st.dataframe(df.head())


if df is None:
    st.info("Por favor cargue un archivo CSV para continuar.")
    st.stop()


# Selecci√≥n de variables
with st.sidebar:
    st.header("2. Selecci√≥n de Variables")
    column_names = df.columns.tolist()

    selected_features = st.multiselect("Variables Independientes (X):", column_names, default=column_names[:-1])
    selected_target = st.selectbox("Variable Dependiente (Y):", column_names, index=len(column_names)-1)

if selected_target in selected_features:
    st.error("‚ùå La variable Y no puede estar incluida en X.")
    st.stop()

# Filtrar y preparar datos
# Asegurarse de que las columnas X sean num√©ricas antes de convertirlas a valores (np.number)
numeric_df = df[selected_features].select_dtypes(include=np.number)

# Verificar si hay variables X num√©ricas seleccionadas
if numeric_df.empty:
     st.error("‚ùå No se encontraron columnas num√©ricas v√°lidas para las Variables Independientes (X).")
     st.stop()
    
X = numeric_df.values
y = df[selected_target].values # La Y se toma directamente de la columna seleccionada

# Control de la cantidad de datos
if X.shape[0] < 5:
    st.error("‚ö† Se requieren al menos 5 observaciones para entrenar un modelo.")
    st.stop()

# Divisi√≥n en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Selecci√≥n del modelo
with st.sidebar:
    st.header("3. Modelo de Regresi√≥n")
    models = {
        "Regresi√≥n Lineal": LinearRegression,
        "√Årbol de Decisi√≥n": DecisionTreeRegressor,
        "Random Forest": RandomForestRegressor,
        "M√°quinas de Soporte Vectorial (SVR)": SVR,
    }

    model_name = st.selectbox("Modelo:", list(models.keys()))

    # Par√°metros espec√≠ficos para Random Forest
    if model_name == "Random Forest":
        n_estimators = st.slider("N¬∞ de √°rboles:", 10, 300, 100)
        max_depth = st.slider("Profundidad m√°xima:", 2, 30, 10)


if st.sidebar.button("‚úÖ Entrenar Modelo"):
    model_class = models[model_name]

    # Inicializaci√≥n del modelo con o sin hiperpar√°metros
    if model_name == "Random Forest":
        model = model_class(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
    else:
        model = model_class()

    # Entrenamiento
    model.fit(X_train, y_train)

    # Predicciones
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # C√°lculo y presentaci√≥n de M√©tricas
    st.header("üìä Resultados del Modelo")
    metrics = pd.DataFrame([
        calculate_metrics(y_train, y_train_pred, "Entrenamiento"),
        calculate_metrics(y_test, y_test_pred, "Validaci√≥n"),
    ]).set_index("Conjunto")
    st.table(metrics)

    # ---------------------------------------------
    # Gr√°ficos Real vs Predicho (Entrenamiento y Validaci√≥n)
    # ---------------------------------------------
    st.header("üìà Gr√°ficos: Real vs Predicho")

    # Determinar el rango com√∫n para los ejes
    min_val = min(y_train.min(), y_test.min(), y_train_pred.min(), y_test_pred.min())
    max_val = max(y_train.max(), y_test.max(), y_train_pred.max(), y_test_pred.max())

    # Crear dos columnas para mostrar las dos gr√°ficas lado a lado
    col1, col2 = st.columns(2)

    with col1:
        # Gr√°fico de Entrenamiento
        fig_train, ax_train = plt.subplots(figsize=(6, 6))
        ax_train.scatter(y_train, y_train_pred, alpha=0.6, color='blue')
        ax_train.plot([min_val, max_val], [min_val, max_val], '--', color='red') # L√≠nea 1:1
        ax_train.set_xlabel(f"Real ({selected_target})")
        ax_train.set_ylabel(f"Predicho ({selected_target})")
        ax_train.set_title("Conjunto de Entrenamiento")
        ax_train.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig_train)

    with col2:
        # Gr√°fico de Validaci√≥n (Test)
        fig_test, ax_test = plt.subplots(figsize=(6, 6))
        ax_test.scatter(y_test, y_test_pred, alpha=0.6, color='green')
        ax_test.plot([min_val, max_val], [min_val, max_val], '--', color='red') # L√≠nea 1:1
        ax_test.set_xlabel(f"Real ({selected_target})")
        ax_test.set_ylabel(f"Predicho ({selected_target})")
        ax_test.set_title("Conjunto de Validaci√≥n")
        ax_test.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig_test)

